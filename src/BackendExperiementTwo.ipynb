{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Backend Experiment Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_details=\"\"\"\n",
    "Basically you would put your hackathon idea in a text box\n",
    "and we would run like 3 llm chains in the background\n",
    "One for frontend one for backend, and then feed both chains into the last one which evaluates the two first chains if its feasible or not, and if it isn't, calls the first two chains again\n",
    "The first two will also return design specifications, eg an outline of the frontend and backend\n",
    "maybe another textbox in the frontend for skills/target categories\n",
    "\"\"\"\n",
    "project_technologies=\"\"\"\n",
    "OpenAI API\n",
    "StreamLit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Chain No. 1: Feature Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVP Backend Features:\n",
      "1. Text Processing: The backend should be able to receive the hackathon idea entered in the text box and process it using natural language processing techniques. This includes tasks such as tokenization, part-of-speech tagging, and named entity recognition.\n",
      "\n",
      "2. LLM Chain Execution: The backend should execute three LLM (Language Model) chains in the background. One chain for the frontend, one for the backend, and one for evaluating the feasibility of the idea. The backend should handle the execution and coordination of these chains.\n",
      "\n",
      "3. Feasibility Evaluation: The backend should evaluate the feasibility of the hackathon idea by comparing the outputs of the frontend and backend LLM chains. It should analyze the generated design specifications and determine if they align with each other. If the evaluation indicates that the idea is not feasible, the backend should trigger the execution of the frontend and backend LLM chains again.\n",
      "\n",
      "Additional Backend Features:\n",
      "1. Skill/Target Category Matching: The backend can include a feature where the frontend provides additional information about the skills or target categories related to the hackathon idea. The backend can process this information and use it to refine the evaluation process. It can match the skills/target categories with the generated design specifications to provide more accurate feasibility evaluation.\n",
      "\n",
      "2. Error Handling and Retry Mechanism: The backend should handle any errors that occur during the execution of the LLM chains or the feasibility evaluation. It should have a retry mechanism in place to handle failures and ensure the smooth functioning of the system.\n",
      "\n",
      "3. User Authentication and Authorization: If the hackathon project involves user-specific features, the backend should include user authentication and authorization mechanisms. This ensures that only authorized users can access and interact with the system.\n",
      "\n",
      "4. Logging and Monitoring: The backend should have logging and monitoring capabilities to track the execution of the LLM chains, feasibility evaluation, and any other backend processes. This helps in debugging, performance monitoring, and identifying any potential issues.\n",
      "\n",
      "5. Scalability and Performance Optimization: As the system may need to handle multiple hackathon ideas simultaneously, the backend should be designed to be scalable and optimized for performance. This can involve techniques such as load balancing, caching, and efficient resource utilization.\n",
      "\n",
      "6. API Integration: The backend can integrate with external APIs, such as the OpenAI API, to leverage additional functionalities or services. This can enhance the capabilities of the system and provide more accurate evaluations or suggestions.\n",
      "\n",
      "7. Data Storage and Retrieval: If the system needs to store and retrieve data, the backend should include a database or data storage mechanism. This allows for persistence of hackathon ideas, user information, or any other relevant data.\n",
      "\n",
      "8. Security: The backend should implement security measures to protect the system and user data. This can include encryption, secure communication protocols, and input validation to prevent any potential security vulnerabilities.\n",
      "\n",
      "9. Error Reporting and Notifications: The backend can include a feature to report errors or send notifications to the system administrators or users. This helps in identifying and resolving issues promptly.\n",
      "\n",
      "10. Documentation and API Reference: The backend should provide comprehensive documentation and an API reference guide for developers who want to integrate or interact with the system. This ensures ease of use and promotes collaboration.\n",
      "\n",
      "Note: The features listed above are based on the given project description and tech stack. The actual implementation may vary depending on specific requirements and constraints.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-3.5-turbo\")\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"project_details\", \"project_technologies\"],\n",
    "    template=\"\"\"\n",
    "    Given the following project description and tech stack, identify and elaborate on the key backend features that would be necessary for development. The backend features should not involve any frontend components or styling. The backend features should be described in terms of capabilities.\n",
    "    This project is a hackathon project. Break apart the features into MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "    Project description: {project_details}\n",
    "    Technologies: {project_technologies}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "backend_features = chain.run({\n",
    "    'project_details': project_details,\n",
    "    'project_technologies': project_technologies\n",
    "})\n",
    "print(backend_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chain Two:  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Specification:\n",
      "\n",
      "MVP Backend Features:\n",
      "1. Text Processing:\n",
      "   - Technology: Natural Language Processing (NLP) libraries (e.g., NLTK, spaCy)\n",
      "   - Architecture: The backend should receive the hackathon idea entered in the text box and process it using NLP techniques such as tokenization, part-of-speech tagging, and named entity recognition.\n",
      "   - Inputs: Hackathon idea text\n",
      "   - Outputs: Processed text with tokenization, part-of-speech tags, and named entities\n",
      "\n",
      "2. LLM Chain Execution:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should execute three LLM chains in the background - one for the frontend, one for the backend, and one for evaluating the feasibility of the idea.\n",
      "   - Inputs: None\n",
      "   - Outputs: Generated design specifications from each LLM chain\n",
      "\n",
      "3. Feasibility Evaluation:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should compare the outputs of the frontend and backend LLM chains to evaluate the feasibility of the hackathon idea. It should analyze the generated design specifications and determine if they align with each other.\n",
      "   - Inputs: Generated design specifications from frontend and backend LLM chains\n",
      "   - Outputs: Feasibility evaluation result (feasible or not feasible)\n",
      "\n",
      "Additional Backend Features:\n",
      "1. Skill/Target Category Matching:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend can process additional information about the skills or target categories related to the hackathon idea provided by the frontend. It can match the skills/target categories with the generated design specifications to provide more accurate feasibility evaluation.\n",
      "   - Inputs: Additional information about skills/target categories\n",
      "   - Outputs: Refined feasibility evaluation result\n",
      "\n",
      "2. Error Handling and Retry Mechanism:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should handle errors that occur during the execution of the LLM chains or the feasibility evaluation. It should have a retry mechanism in place to handle failures and ensure the smooth functioning of the system.\n",
      "   - Inputs: None\n",
      "   - Outputs: Error handling and retry mechanism\n",
      "\n",
      "3. User Authentication and Authorization:\n",
      "   - Technology: Python, Authentication library (e.g., Flask-Login, Django-Auth)\n",
      "   - Architecture: The backend should include user authentication and authorization mechanisms if the hackathon project involves user-specific features. This ensures that only authorized users can access and interact with the system.\n",
      "   - Inputs: User credentials\n",
      "   - Outputs: User authentication and authorization status\n",
      "\n",
      "4. Logging and Monitoring:\n",
      "   - Technology: Logging library (e.g., Python logging module)\n",
      "   - Architecture: The backend should have logging and monitoring capabilities to track the execution of the LLM chains, feasibility evaluation, and other backend processes. This helps in debugging, performance monitoring, and identifying potential issues.\n",
      "   - Inputs: None\n",
      "   - Outputs: Log files and monitoring data\n",
      "\n",
      "5. Scalability and Performance Optimization:\n",
      "   - Technology: Load balancing software (e.g., Nginx), Caching mechanisms (e.g., Redis), Performance optimization techniques\n",
      "   - Architecture: The backend should be designed to be scalable and optimized for performance to handle multiple hackathon ideas simultaneously. Techniques such as load balancing, caching, and efficient resource utilization can be employed.\n",
      "   - Inputs: High traffic and concurrent requests\n",
      "   - Outputs: Scalable and performant backend system\n",
      "\n",
      "6. API Integration:\n",
      "   - Technology: Python, OpenAI API\n",
      "   - Architecture: The backend can integrate with external APIs, such as the OpenAI API, to leverage additional functionalities or services. This can enhance the capabilities of the system and provide more accurate evaluations or suggestions.\n",
      "   - Inputs: API requests and responses\n",
      "   - Outputs: Integrated API functionalities\n",
      "\n",
      "7. Data Storage and Retrieval:\n",
      "   - Technology: Database (e.g., PostgreSQL, MongoDB)\n",
      "   - Architecture: If the system needs to store and retrieve data, the backend should include a database or data storage mechanism. This allows for persistence of hackathon ideas, user information, or any other relevant data.\n",
      "   - Inputs: Data to be stored or retrieved\n",
      "   - Outputs: Stored or retrieved data\n",
      "\n",
      "8. Security:\n",
      "   - Technology: Encryption libraries (e.g., bcrypt), Secure communication protocols (e.g., HTTPS), Input validation techniques\n",
      "   - Architecture: The backend should implement security measures to protect the system and user data. This can include encryption, secure communication protocols, and input validation to prevent any potential security vulnerabilities.\n",
      "   - Inputs: User data, system data\n",
      "   - Outputs: Secured system and data\n",
      "\n",
      "9. Error Reporting and Notifications:\n",
      "   - Technology: Notification libraries (e.g., email notification library)\n",
      "   - Architecture: The backend can include a feature to report errors or send notifications to system administrators or users. This helps in identifying and resolving issues promptly.\n",
      "   - Inputs: Error or notification triggers\n",
      "   - Outputs: Error reports or notifications\n",
      "\n",
      "10. Documentation and API Reference:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "specification_prompt = PromptTemplate(\n",
    "    input_variables=[\"backend_features\", \"project_technologies\"],\n",
    "    template=\"\"\"\n",
    "    Given the extracted backend features and the specified skills/technologies, create a detailed technical specification. \n",
    "    This specification should include the technologies to be used, the architecture, the different routes/endpoints, their inputs and outputs, and any potential hardware and startup costs.\n",
    "    However, they should be split into two categories: MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "    You should ignore the technologies for the frontend and focus on the backend.\n",
    "    Please also mention any other technical considerations.\n",
    "    \n",
    "    Backend Features: {backend_features}\n",
    "    \n",
    "    Project Technologies: {project_technologies}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "specification_chain = LLMChain(llm=llm, prompt=specification_prompt)\n",
    "specification = specification_chain.run({\n",
    "    'backend_features': backend_features,\n",
    "    'project_technologies': project_technologies\n",
    "})\n",
    "print(specification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chain Three: AI Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "approval_prompt = PromptTemplate(\n",
    "    input_variables=[\"technical_specification\", \"aspect\", \"group_size\"],\n",
    "    template=\"\"\"\n",
    "    Given the developed technical specification, conduct a thorough review of the MVP Features only for any inconsistencies or issues. The MVP Features are specifically listed under the heading 'MVP Features'. \n",
    "Please completely disregard any features or sections listed under 'Additional Features' or any similar headers.\n",
    "\n",
    "This specification is only for the {aspect} aspect of the project, and should not be evaluated for other aspects, such as backend and database requirements.\n",
    "\n",
    "Also, evaluate whether the MVP Features, as described, can be realistically completed within the two day hackathon for {group_size} people, considering their complexity and the technology stack required.\n",
    "\n",
    "If the MVP Features can be realistically completed within the two day hackathon for {group_size} people considering their complexity and the technology stack required, and there are no inconsistencies or issues, output '1'.\n",
    "If not, output '0'. In the next line, provide comments explaining the reasons for disapproval, if any.\n",
    "\n",
    "Technical Specification: {technical_specification}\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "approval_chain = LLMChain(llm=llm, prompt=approval_prompt)\n",
    "approval = approval_chain.run({\n",
    "    'technical_specification': specification,\n",
    "    'aspect': 'backend',\n",
    "    'group_size': '4'\n",
    "})\n",
    "print(approval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Architect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
