{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Backend Experiment Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.agents import Tool\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_details=\"\"\"\n",
    "Basically you would put your hackathon idea in a text box\n",
    "and we would run like 3 llm chains in the background\n",
    "One for frontend one for backend, and then feed both chains into the last one which evaluates the two first chains if its feasible or not, and if it isn't, calls the first two chains again\n",
    "The first two will also return design specifications, eg an outline of the frontend and backend\n",
    "maybe another textbox in the frontend for skills/target categories\n",
    "\"\"\"\n",
    "project_technologies=\"\"\"\n",
    "OpenAI API\n",
    "StreamLit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Chain No. 1: Feature Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVP Backend Features:\n",
      "1. Text Processing: The backend should be able to receive the hackathon idea entered in the text box and process it using natural language processing techniques. This includes tasks such as tokenization, part-of-speech tagging, and named entity recognition.\n",
      "\n",
      "2. LLM Chain Execution: The backend should execute three LLM (Language Model) chains in the background. One chain for the frontend, one for the backend, and one for evaluating the feasibility of the idea. The backend should handle the execution and coordination of these chains.\n",
      "\n",
      "3. Feasibility Evaluation: The backend should evaluate the feasibility of the hackathon idea by comparing the outputs of the frontend and backend LLM chains. It should analyze the design specifications generated by the chains and determine if they align or if further iterations are required.\n",
      "\n",
      "4. Iterative Loop: If the feasibility evaluation determines that further iterations are required, the backend should call the frontend and backend LLM chains again to generate updated design specifications. This iterative loop ensures that the idea is refined until it becomes feasible.\n",
      "\n",
      "Additional Backend Features:\n",
      "1. Skill/Target Category Matching: The backend can include a feature where users can enter their skills or target categories in a separate text box. The backend should process this input and match it with the hackathon idea to provide relevant suggestions or recommendations.\n",
      "\n",
      "2. User Authentication: To provide a personalized experience, the backend can implement user authentication. This would allow users to save their hackathon ideas, track their progress, and access their previous submissions.\n",
      "\n",
      "3. Database Integration: The backend can integrate with a database to store and retrieve hackathon ideas, user information, and other relevant data. This would enable persistence and scalability of the application.\n",
      "\n",
      "4. Error Handling and Logging: The backend should handle errors gracefully and provide meaningful error messages to the users. Additionally, implementing logging capabilities would help in debugging and monitoring the application's performance.\n",
      "\n",
      "5. API Integration: The backend can integrate with external APIs to enhance the functionality of the application. For example, it can integrate with project management tools to create tasks or with communication platforms to send notifications.\n",
      "\n",
      "6. Performance Optimization: As the application scales, the backend should optimize its performance. This can include techniques such as caching, load balancing, and query optimization to ensure fast and efficient processing of requests.\n",
      "\n",
      "7. Security Measures: The backend should implement security measures to protect user data and prevent unauthorized access. This can include encryption of sensitive information, implementing secure communication protocols, and following best practices for secure coding.\n",
      "\n",
      "8. Deployment and Scalability: The backend should be deployable on a cloud platform to ensure scalability and availability. It should be able to handle a large number of concurrent requests and scale horizontally as the user base grows.\n",
      "\n",
      "By focusing on the MVP features, the development team can deliver a working prototype that demonstrates the core functionality of the application. The additional features can be implemented in subsequent iterations or as stretch goals, depending on the available time and resources during the hackathon.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-3.5-turbo\")\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"project_details\", \"project_technologies\"],\n",
    "    template=\"\"\"\n",
    "    Given the following project description and tech stack, identify and elaborate on the key backend features that would be necessary for development. The backend features should not involve any frontend components or styling. The backend features should be described in terms of capabilities.\n",
    "    This project is a hackathon project. Break apart the features into MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "    Project description: {project_details}\n",
    "    Technologies: {project_technologies}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "backend_features = chain.run({\n",
    "    'project_details': project_details,\n",
    "    'project_technologies': project_technologies\n",
    "})\n",
    "print(backend_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chain Two:  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Specification:\n",
      "\n",
      "MVP Backend Features:\n",
      "1. Text Processing:\n",
      "   - Technology: OpenAI API\n",
      "   - Architecture: The backend should receive the hackathon idea entered in the text box and send it to the OpenAI API for natural language processing. The API will perform tasks such as tokenization, part-of-speech tagging, and named entity recognition.\n",
      "   - Inputs: Hackathon idea entered in the text box.\n",
      "   - Outputs: Processed text with tokenization, part-of-speech tagging, and named entity recognition.\n",
      "\n",
      "2. LLM Chain Execution:\n",
      "   - Technology: OpenAI API\n",
      "   - Architecture: The backend should execute three LLM chains in the background - one for the frontend, one for the backend, and one for evaluating the feasibility of the idea. The backend will handle the execution and coordination of these chains using the OpenAI API.\n",
      "   - Inputs: Processed hackathon idea.\n",
      "   - Outputs: Design specifications generated by the frontend and backend LLM chains.\n",
      "\n",
      "3. Feasibility Evaluation:\n",
      "   - Technology: OpenAI API\n",
      "   - Architecture: The backend should evaluate the feasibility of the hackathon idea by comparing the outputs of the frontend and backend LLM chains. It will analyze the design specifications generated by the chains and determine if they align or if further iterations are required.\n",
      "   - Inputs: Design specifications generated by the frontend and backend LLM chains.\n",
      "   - Outputs: Feasibility evaluation result (feasible or further iterations required).\n",
      "\n",
      "4. Iterative Loop:\n",
      "   - Technology: OpenAI API\n",
      "   - Architecture: If the feasibility evaluation determines that further iterations are required, the backend should call the frontend and backend LLM chains again to generate updated design specifications. This iterative loop ensures that the idea is refined until it becomes feasible.\n",
      "   - Inputs: Feasibility evaluation result.\n",
      "   - Outputs: Updated design specifications.\n",
      "\n",
      "Additional Backend Features:\n",
      "1. Skill/Target Category Matching:\n",
      "   - Technology: OpenAI API\n",
      "   - Architecture: The backend can include a feature where users can enter their skills or target categories in a separate text box. The backend will process this input and match it with the hackathon idea to provide relevant suggestions or recommendations.\n",
      "   - Inputs: User-entered skills or target categories.\n",
      "   - Outputs: Relevant suggestions or recommendations.\n",
      "\n",
      "2. User Authentication:\n",
      "   - Technology: StreamLit\n",
      "   - Architecture: The backend can implement user authentication using StreamLit. This will allow users to save their hackathon ideas, track their progress, and access their previous submissions.\n",
      "   - Inputs: User credentials (username, password).\n",
      "   - Outputs: User authentication status.\n",
      "\n",
      "3. Database Integration:\n",
      "   - Technology: StreamLit, Database (e.g., MySQL, PostgreSQL)\n",
      "   - Architecture: The backend can integrate with a database to store and retrieve hackathon ideas, user information, and other relevant data. This will enable persistence and scalability of the application.\n",
      "   - Inputs: Hackathon ideas, user information.\n",
      "   - Outputs: Stored hackathon ideas, user information.\n",
      "\n",
      "4. Error Handling and Logging:\n",
      "   - Technology: StreamLit\n",
      "   - Architecture: The backend should handle errors gracefully and provide meaningful error messages to the users. Additionally, implementing logging capabilities will help in debugging and monitoring the application's performance.\n",
      "   - Inputs: Errors encountered during the application's execution.\n",
      "   - Outputs: Error messages, logs.\n",
      "\n",
      "5. API Integration:\n",
      "   - Technology: StreamLit, External APIs\n",
      "   - Architecture: The backend can integrate with external APIs to enhance the functionality of the application. For example, it can integrate with project management tools to create tasks or with communication platforms to send notifications.\n",
      "   - Inputs: Relevant data to be sent to external APIs.\n",
      "   - Outputs: Responses from external APIs.\n",
      "\n",
      "6. Performance Optimization:\n",
      "   - Technology: StreamLit, Caching mechanisms, Load balancers\n",
      "   - Architecture: As the application scales, the backend should optimize its performance. This can include techniques such as caching, load balancing, and query optimization to ensure fast and efficient processing of requests.\n",
      "   - Inputs: Application performance metrics, user requests.\n",
      "   - Outputs: Optimized application performance.\n",
      "\n",
      "7. Security Measures:\n",
      "   - Technology: StreamLit, Encryption libraries, Secure communication protocols\n",
      "   - Architecture: The backend should implement security measures to protect user data and prevent unauthorized access. This can include encryption of sensitive information, implementing secure communication protocols, and following best practices for secure coding.\n",
      "   - Inputs: User data, communication requests.\n",
      "   - Outputs: Secured user data, protected communication.\n",
      "\n",
      "8. Deployment and Scalability:\n",
      "   - Technology: Cloud platform (e.g., AWS, Google Cloud)\n",
      "   - Architecture: The backend should be deployable on a cloud platform to ensure scalability and availability. It should be able to handle a large number of concurrent requests and scale horizontally as the user base grows.\n",
      "   - Inputs: Application deployment configurations, user requests.\n",
      "   - Outputs: Deployed and\n"
     ]
    }
   ],
   "source": [
    "specification_prompt = PromptTemplate(\n",
    "    input_variables=[\"backend_features\", \"project_technologies\"],\n",
    "    template=\"\"\"\n",
    "    Given the extracted backend features and the specified skills/technologies, create a detailed technical specification. \n",
    "    This specification should include the technologies to be used, the architecture, the different routes/endpoints, their inputs and outputs, and any potential hardware and startup costs.\n",
    "    However, they should be split into two categories: MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "    You should ignore the technologies for the frontend and focus on the backend.\n",
    "    Please also mention any other technical considerations.\n",
    "    \n",
    "    Backend Features: {backend_features}\n",
    "    \n",
    "    Project Technologies: {project_technologies}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "specification_chain = LLMChain(llm=llm, prompt=specification_prompt)\n",
    "specification = specification_chain.run({\n",
    "    'backend_features': backend_features,\n",
    "    'project_technologies': project_technologies\n",
    "})\n",
    "print(specification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chain Three: AI Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"approval\": \"1\", \"comments\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "approval_prompt = PromptTemplate(\n",
    "    input_variables=[\"technical_specification\", \"aspect\", \"group_size\", \"group_experience\"],\n",
    "    template=\"\"\"\n",
    "    Given the developed technical specification, conduct a thorough review of the MVP Features only for any inconsistencies or issues. \n",
    "    Also, evaluate whether the MVP Features, can be realistically completed within the two day hackathon for {group_size} people, considering the complexity and the technology stack required.\n",
    "    \n",
    "    The MVP Features are specifically listed under the heading 'MVP Features'. \n",
    "    Please completely disregard any features or sections listed under 'Additional Features' or any similar headers.\n",
    "    This specification is only for the {aspect} aspect of the project, and should not be evaluated for other aspects.\n",
    "\n",
    "    Answer this question: Can the MVP Features be realistically completed within the two day hackathon for {group_size} people with this skill level: {group_experience}?\n",
    "    Output only a json with keys 'approval' and 'comments'. \n",
    "    If yes, the value of 'approval' should be '1' and the value of 'comments' should be an empty string\n",
    "    If not, the value of 'approval' should be '0' and the value of 'comments' should be a string with the issues and inconsistencies listed.\n",
    "\n",
    "    Technical Specification: {technical_specification}\n",
    "    \n",
    "    Output only a json with keys 'approval' and 'comments'. \n",
    "    \"\"\"\n",
    ")\n",
    "advanced_llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-4\")\n",
    "approval_chain = LLMChain(llm=advanced_llm, prompt=approval_prompt)\n",
    "approval = approval_chain.run({\n",
    "    'technical_specification': specification,\n",
    "    'aspect': 'backend',\n",
    "    'group_size': '4',\n",
    "    'group_experience': \"experienced\"\n",
    "})\n",
    "print(approval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Architect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
