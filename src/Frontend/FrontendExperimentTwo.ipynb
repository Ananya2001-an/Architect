{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Experiment Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import openai\n",
    "from langchain.agents import Tool\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import asyncio\n",
    "\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from pydantic import Extra\n",
    "\n",
    "from langchain.schema import BaseLanguageModel\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForChainRun,\n",
    "    CallbackManagerForChainRun,\n",
    ")\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.schema import BasePromptTemplate\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_details=\"\"\"\n",
    "Basically you would put your hackathon idea in a text box\n",
    "and we would run like 3 llm chains in the background\n",
    "One for frontend one for backend, and then feed both chains into the last one which evaluates the two first chains if its feasible or not, and if it isn't, calls the first two chains again\n",
    "The first two will also return design specifications, eg an outline of the frontend and backend\n",
    "maybe another textbox in the frontend for skills/target categories\n",
    "\"\"\"\n",
    "project_technologies=\"\"\"\n",
    "OpenAI API\n",
    "StreamLit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Frontend Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def frontend_func(\n",
    "        inputs: Dict[str, Any],\n",
    "        llm: BaseLanguageModel,\n",
    "        advanced_llm: BaseLanguageModel,\n",
    "    ) -> str:\n",
    "        # Feature Extraction\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"project_details\", \"project_technologies\"],\n",
    "            template=\"\"\"\n",
    "            Given the following project description and tech stack, identify and elaborate on the key frontend features that would be necessary for development. The frontend features should not involve backend api calls or database interactions. The frontend features should be described in terms of user stories or detailed feature requirements.\n",
    "            This project is a hackathon project. Break apart the features into MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "            Project description: {project_details}\n",
    "            Technologies: {project_technologies}\n",
    "            \"\"\"\n",
    "        )\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        frontend_features = await chain.arun(inputs)\n",
    "        \n",
    "        # Specification Creation\n",
    "        specification_prompt = PromptTemplate(\n",
    "            input_variables=[\"frontend_features\", \"project_technologies\"],\n",
    "            template=\"\"\"\n",
    "            Given the extracted frontend features, create a detailed technical specification. \n",
    "            This specification should include the technologies to be used, the architecture, pages to be developed, and the components required for each page.\n",
    "            However, they should be split into two categories: MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "            You should ignore the technologies for the backend and focus on the frontend.\n",
    "            Please also mention any other technical considerations.\n",
    "\n",
    "            Frontend Features: {frontend_features}\n",
    "            Project Technologies: {project_technologies}\n",
    "            \"\"\"\n",
    "        )\n",
    "        specification_chain = LLMChain(llm=llm, prompt=specification_prompt)\n",
    "        specification = await specification_chain.arun({\n",
    "            'frontend_features': frontend_features,\n",
    "            'project_technologies': inputs['project_technologies']\n",
    "        })\n",
    "\n",
    "        # AI Approval\n",
    "        \n",
    "        approval_prompt = PromptTemplate(\n",
    "            input_variables=[\"technical_specification\", \"aspect\", \"group_size\", \"group_experience\"],\n",
    "            template=\"\"\"\n",
    "            Given the developed technical specification, conduct a thorough review of the MVP Features only for any inconsistencies or issues. \n",
    "            Also, evaluate whether the MVP Features, can be realistically completed within the two day hackathon for {group_size} people.\n",
    "            \n",
    "            The MVP Features are specifically listed under the heading 'MVP Features'. \n",
    "            Please completely disregard any features or sections listed under 'Additional Features' or any similar headers.\n",
    "            This specification is only for the {aspect} aspect of the project, and should not be evaluated for other aspects.\n",
    "\n",
    "            Answer this question: Can the MVP Features be realistically completed within the two day hackathon for {group_size} people with this skill level: {group_experience}?\n",
    "            Output only a json with keys 'approval' and 'comments'. \n",
    "            If yes, the value of 'approval' should be '1' and the value of 'comments' should be an empty string\n",
    "            If not, the value of 'approval' should be '0' and the value of 'comments' should be a string with the issues and inconsistencies listed.\n",
    "\n",
    "            Technical Specification: {technical_specification}\n",
    "            \n",
    "            Output only a json with keys 'approval' and 'comments'. \n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        approval_chain = LLMChain(llm=advanced_llm, prompt=approval_prompt)\n",
    "        approval = await approval_chain.arun({\n",
    "            'technical_specification': specification,\n",
    "            'aspect': 'frontend',\n",
    "            'group_size': inputs['group_size'],\n",
    "            'group_experience': inputs['group_experience']\n",
    "        })\n",
    "        \n",
    "        approvals_object = json.loads(approval)\n",
    "        \n",
    "        return_obj = {\n",
    "            'approval': approvals_object['approval'],\n",
    "            'comments': approvals_object['comments'],\n",
    "            'idea': inputs['project_details'],\n",
    "            'features': frontend_features,\n",
    "            'specifications': specification\n",
    "        }\n",
    "        \n",
    "        return json.dumps(return_obj)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing this custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-3.5-turbo\")\n",
    "advanced_llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-4\")\n",
    "\n",
    "output = await frontend_func(\n",
    "    inputs = {\n",
    "        'project_details': project_details,\n",
    "        \"project_technologies\": project_technologies,\n",
    "        \"group_size\": 4,\n",
    "        \"group_experience\": \"experienced\"\n",
    "    },\n",
    "    llm=llm,\n",
    "    advanced_llm=advanced_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approval': '1',\n",
       " 'comments': '',\n",
       " 'idea': \"\\nBasically you would put your hackathon idea in a text box\\nand we would run like 3 llm chains in the background\\nOne for frontend one for backend, and then feed both chains into the last one which evaluates the two first chains if its feasible or not, and if it isn't, calls the first two chains again\\nThe first two will also return design specifications, eg an outline of the frontend and backend\\nmaybe another textbox in the frontend for skills/target categories\\n\",\n",
       " 'features': 'MVP Frontend Features:\\n1. User Input: The frontend should have a text box where users can input their hackathon idea.\\n2. Design Specifications: The frontend should display the design specifications generated by the first chain, which includes an outline of the frontend and backend.\\n3. Feasibility Evaluation: The frontend should display the evaluation result from the last chain, indicating whether the idea is feasible or not.\\n4. Retry Functionality: If the idea is deemed not feasible, the frontend should provide a button or option to allow users to retry and generate new design specifications.\\n\\nAdditional Frontend Features:\\n1. Skill/Target Category Selection: The frontend can include a dropdown or checkbox options for users to select their skills or target categories related to their hackathon idea.\\n2. Real-time Feedback: As users type their hackathon idea in the text box, the frontend can provide real-time suggestions or feedback to improve the idea or provide additional information.\\n3. Progress Indicators: The frontend can display progress indicators to show the status of the llm chains running in the background, providing transparency to the users.\\n4. Error Handling: If any errors occur during the llm chain processing, the frontend should display appropriate error messages to the users and provide guidance on how to resolve the issue.\\n5. Save/Export Functionality: The frontend can include options for users to save or export the generated design specifications for future reference or sharing with team members.\\n\\nBy implementing the MVP frontend features, users will be able to input their hackathon idea, generate design specifications, and receive an evaluation of its feasibility. The additional frontend features enhance the user experience by allowing them to select skills/target categories, receive real-time feedback, track the progress, handle errors effectively, and save/export the generated design specifications.',\n",
       " 'specifications': \"Technical Specification:\\n\\nTechnologies:\\n1. OpenAI API: The OpenAI API will be used to generate design specifications and evaluate the feasibility of the hackathon idea.\\n2. StreamLit: StreamLit will be used as the frontend framework to develop the user interface and handle the interaction between the user and the backend.\\n\\nArchitecture:\\nThe frontend will follow a client-server architecture, with the StreamLit application running on the client-side and communicating with the backend through API calls to the OpenAI API.\\n\\nPages to be Developed:\\n1. Home Page: This page will contain the user input text box where users can input their hackathon idea.\\n2. Design Specifications Page: This page will display the design specifications generated by the first chain, including the outline of the frontend and backend.\\n3. Feasibility Evaluation Page: This page will display the evaluation result from the last chain, indicating whether the idea is feasible or not.\\n4. Retry Functionality Page: If the idea is deemed not feasible, this page will provide a button or option to allow users to retry and generate new design specifications.\\n\\nComponents Required for Each Page:\\n1. Home Page:\\n   - Text Box: A text box component will be used to capture the user's hackathon idea input.\\n\\n2. Design Specifications Page:\\n   - Text Display: A text display component will be used to show the generated design specifications.\\n\\n3. Feasibility Evaluation Page:\\n   - Text Display: A text display component will be used to show the evaluation result.\\n\\n4. Retry Functionality Page:\\n   - Button: A button component will be used to trigger the retry functionality.\\n\\nAdditional Technical Considerations:\\n1. Real-time Feedback: To provide real-time suggestions or feedback as users type their hackathon idea, the frontend will need to implement event listeners on the text box component and make API calls to the OpenAI API to retrieve the feedback.\\n\\n2. Progress Indicators: To display progress indicators for the llm chains running in the background, the frontend can use loading spinners or progress bars that update based on the status of the API calls.\\n\\n3. Error Handling: The frontend should handle any errors that occur during the llm chain processing. It should display appropriate error messages to the users and provide guidance on how to resolve the issue. This can be achieved by catching and handling exceptions thrown by the API calls.\\n\\n4. Save/Export Functionality: To implement the save/export functionality, the frontend can include buttons or options that trigger the saving or exporting of the generated design specifications. This can be done by either storing the specifications in a database or generating a downloadable file for the user.\\n\\nBy implementing the MVP frontend features, users will be able to input their hackathon idea, generate design specifications, and receive an evaluation of its feasibility. The additional frontend features enhance the user experience by allowing them to select skills/target categories, receive real-time feedback, track the progress, handle errors effectively, and save/export the generated design specifications.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "architect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
