{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Backend Experiment Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.agents import Tool\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_details=\"\"\"\n",
    "Basically you would put your hackathon idea in a text box\n",
    "and we would run like 3 llm chains in the background\n",
    "One for frontend one for backend, and then feed both chains into the last one which evaluates the two first chains if its feasible or not, and if it isn't, calls the first two chains again\n",
    "The first two will also return design specifications, eg an outline of the frontend and backend\n",
    "maybe another textbox in the frontend for skills/target categories\n",
    "\"\"\"\n",
    "project_technologies=\"\"\"\n",
    "OpenAI API\n",
    "StreamLit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Chain No. 1: Feature Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVP Backend Features:\n",
      "1. Text Processing: The backend should be able to receive the hackathon idea entered in the text box and process it using natural language processing techniques. This includes tasks such as tokenization, part-of-speech tagging, and named entity recognition.\n",
      "\n",
      "2. LLM Chain Execution: The backend should execute three LLM (Language Model) chains in the background. One chain for the frontend, one for the backend, and one for evaluating the feasibility of the idea. The backend should handle the execution and coordination of these chains.\n",
      "\n",
      "3. Feasibility Evaluation: The backend should evaluate the feasibility of the hackathon idea by comparing the outputs of the frontend and backend LLM chains. It should analyze the generated design specifications and determine if they align with each other. If the evaluation indicates that the idea is not feasible, the backend should trigger the execution of the frontend and backend LLM chains again.\n",
      "\n",
      "Additional Backend Features:\n",
      "1. Skill/Target Category Matching: The backend can include a feature where the frontend provides additional information about the skills or target categories related to the hackathon idea. The backend can process this information and use it to refine the evaluation process. It can match the skills/target categories with the generated design specifications to provide more accurate feasibility evaluation.\n",
      "\n",
      "2. Error Handling and Retry Mechanism: The backend should handle any errors that occur during the execution of the LLM chains or the feasibility evaluation. It should have a retry mechanism in place to handle failures and ensure the smooth functioning of the system.\n",
      "\n",
      "3. User Authentication and Authorization: If the hackathon project involves user-specific features, the backend should include user authentication and authorization mechanisms. This ensures that only authorized users can access and interact with the system.\n",
      "\n",
      "4. Logging and Monitoring: The backend should have logging and monitoring capabilities to track the execution of the LLM chains, feasibility evaluation, and any other backend processes. This helps in debugging, performance monitoring, and identifying any potential issues.\n",
      "\n",
      "5. Scalability and Performance Optimization: As the system may need to handle multiple hackathon ideas simultaneously, the backend should be designed to be scalable and optimized for performance. This can involve techniques such as load balancing, caching, and efficient resource utilization.\n",
      "\n",
      "6. API Integration: The backend can integrate with external APIs, such as the OpenAI API, to leverage additional functionalities or services. This can enhance the capabilities of the system and provide more accurate evaluations or suggestions.\n",
      "\n",
      "7. Data Storage and Retrieval: If the system needs to store and retrieve data, the backend should include a database or data storage mechanism. This allows for persistence of hackathon ideas, user information, or any other relevant data.\n",
      "\n",
      "8. Security: The backend should implement security measures to protect the system and user data. This can include encryption, secure communication protocols, and input validation to prevent any potential security vulnerabilities.\n",
      "\n",
      "9. Error Reporting and Notifications: The backend can include a feature to report errors or notify the system administrators or users about any critical issues. This helps in timely resolution of problems and ensures smooth operation of the system.\n",
      "\n",
      "10. Documentation and API Reference: The backend should provide comprehensive documentation and an API reference guide for developers to understand and utilize the backend features effectively. This includes clear explanations of endpoints, request/response formats, and any required authentication mechanisms.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-3.5-turbo\")\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"project_details\", \"project_technologies\"],\n",
    "    template=\"\"\"\n",
    "    Given the following project description and tech stack, identify and elaborate on the key backend features that would be necessary for development. The backend features should not involve any frontend components or styling. The backend features should be described in terms of capabilities.\n",
    "    This project is a hackathon project. Break apart the features into MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "    Project description: {project_details}\n",
    "    Technologies: {project_technologies}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "backend_features = chain.run({\n",
    "    'project_details': project_details,\n",
    "    'project_technologies': project_technologies\n",
    "})\n",
    "print(backend_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chain Two:  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Specification:\n",
      "\n",
      "MVP Backend Features:\n",
      "1. Text Processing:\n",
      "   - Technology: Natural Language Processing (NLP) libraries (e.g., NLTK, spaCy)\n",
      "   - Architecture: The backend should receive the hackathon idea as input and process it using NLP techniques such as tokenization, part-of-speech tagging, and named entity recognition.\n",
      "   - Inputs: Hackathon idea text\n",
      "   - Outputs: Processed text with tokenized words, tagged parts of speech, and recognized named entities.\n",
      "\n",
      "2. LLM Chain Execution:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should execute three LLM chains (one for the frontend, one for the backend, and one for feasibility evaluation) in the background.\n",
      "   - Inputs: None\n",
      "   - Outputs: Generated design specifications from each LLM chain.\n",
      "\n",
      "3. Feasibility Evaluation:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should compare the outputs of the frontend and backend LLM chains to evaluate the feasibility of the hackathon idea.\n",
      "   - Inputs: Generated design specifications from the frontend and backend LLM chains\n",
      "   - Outputs: Feasibility evaluation result (feasible or not feasible)\n",
      "\n",
      "Additional Backend Features:\n",
      "1. Skill/Target Category Matching:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should process additional information about skills or target categories related to the hackathon idea provided by the frontend. It should match these with the generated design specifications to refine the feasibility evaluation.\n",
      "   - Inputs: Additional information about skills or target categories\n",
      "   - Outputs: Refined feasibility evaluation result\n",
      "\n",
      "2. Error Handling and Retry Mechanism:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should handle errors during LLM chain execution and feasibility evaluation. It should have a retry mechanism to handle failures and ensure system stability.\n",
      "   - Inputs: None\n",
      "   - Outputs: Error handling and retry mechanism for LLM chain execution and feasibility evaluation\n",
      "\n",
      "3. User Authentication and Authorization:\n",
      "   - Technology: Python, Authentication libraries (e.g., Flask-Login, JWT)\n",
      "   - Architecture: The backend should include user authentication and authorization mechanisms if user-specific features are required. This ensures only authorized users can access and interact with the system.\n",
      "   - Inputs: User credentials\n",
      "   - Outputs: User authentication and authorization status\n",
      "\n",
      "4. Logging and Monitoring:\n",
      "   - Technology: Logging libraries (e.g., Python logging module), Monitoring tools (e.g., Prometheus, Grafana)\n",
      "   - Architecture: The backend should have logging and monitoring capabilities to track LLM chain execution, feasibility evaluation, and other backend processes. This helps in debugging, performance monitoring, and issue identification.\n",
      "   - Inputs: None\n",
      "   - Outputs: Logs and monitoring metrics\n",
      "\n",
      "5. Scalability and Performance Optimization:\n",
      "   - Technology: Load balancing tools (e.g., Nginx, HAProxy), Caching mechanisms (e.g., Redis), Performance optimization techniques\n",
      "   - Architecture: The backend should be designed to handle multiple hackathon ideas simultaneously. Techniques like load balancing, caching, and efficient resource utilization should be employed for scalability and performance optimization.\n",
      "   - Inputs: Multiple hackathon ideas\n",
      "   - Outputs: Scalable and optimized backend system\n",
      "\n",
      "6. API Integration:\n",
      "   - Technology: Python, OpenAI API\n",
      "   - Architecture: The backend can integrate with external APIs, such as the OpenAI API, to leverage additional functionalities or services. This enhances the system's capabilities and provides more accurate evaluations or suggestions.\n",
      "   - Inputs: Hackathon idea, API credentials\n",
      "   - Outputs: Enhanced evaluations or suggestions from external APIs\n",
      "\n",
      "7. Data Storage and Retrieval:\n",
      "   - Technology: Database systems (e.g., PostgreSQL, MongoDB)\n",
      "   - Architecture: If data storage and retrieval are required, the backend should include a database or data storage mechanism. This allows for persistence of hackathon ideas, user information, or any other relevant data.\n",
      "   - Inputs: Hackathon ideas, user information\n",
      "   - Outputs: Stored and retrieved data\n",
      "\n",
      "8. Security:\n",
      "   - Technology: Encryption libraries (e.g., bcrypt), Secure communication protocols (e.g., HTTPS), Input validation techniques\n",
      "   - Architecture: The backend should implement security measures to protect the system and user data. This includes encryption, secure communication protocols, and input validation to prevent security vulnerabilities.\n",
      "   - Inputs: User data, system data\n",
      "   - Outputs: Secured system and user data\n",
      "\n",
      "9. Error Reporting and Notifications:\n",
      "   - Technology: Logging libraries, Notification services (e.g., email, SMS)\n",
      "   - Architecture: The backend can include a feature to report errors or notify system administrators or users about critical issues. This ensures timely resolution of problems and smooth operation of the system.\n",
      "   - Inputs: Error information, critical issue notifications\n",
      "   - Outputs: Error reports and notifications\n",
      "\n",
      "10. Documentation and API Reference:\n",
      "    - Technology: Documentation tools (e.g., Swagger, Sphinx)\n",
      "    - Architecture: The\n"
     ]
    }
   ],
   "source": [
    "specification_prompt = PromptTemplate(\n",
    "    input_variables=[\"backend_features\", \"project_technologies\"],\n",
    "    template=\"\"\"\n",
    "    Given the extracted backend features and the specified skills/technologies, create a detailed technical specification. \n",
    "    This specification should include the technologies to be used, the architecture, the different routes/endpoints, their inputs and outputs, and any potential hardware and startup costs.\n",
    "    However, they should be split into two categories: MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "    You should ignore the technologies for the frontend and focus on the backend.\n",
    "    Please also mention any other technical considerations.\n",
    "    \n",
    "    Backend Features: {backend_features}\n",
    "    \n",
    "    Project Technologies: {project_technologies}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "specification_chain = LLMChain(llm=llm, prompt=specification_prompt)\n",
    "specification = specification_chain.run({\n",
    "    'backend_features': backend_features,\n",
    "    'project_technologies': project_technologies\n",
    "})\n",
    "print(specification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chain Three: AI Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"approval\": \"1\", \"comments\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "approval_prompt = PromptTemplate(\n",
    "    input_variables=[\"technical_specification\", \"aspect\", \"group_size\", \"group_experience\"],\n",
    "    template=\"\"\"\n",
    "    Given the developed technical specification, conduct a thorough review of the MVP Features only for any inconsistencies or issues. \n",
    "    Also, evaluate whether the MVP Features, can be realistically completed within the two day hackathon for {group_size} people, considering the complexity and the technology stack required.\n",
    "    \n",
    "    The MVP Features are specifically listed under the heading 'MVP Features'. \n",
    "    Please completely disregard any features or sections listed under 'Additional Features' or any similar headers.\n",
    "    This specification is only for the {aspect} aspect of the project, and should not be evaluated for other aspects.\n",
    "\n",
    "    Answer this question: Can the MVP Features be realistically completed within the two day hackathon for {group_size} people with this skill level:{group_experience}, their complexity and the technology stack required?\n",
    "    Output only a json with keys 'approval' and 'comments'. \n",
    "    If yes, the value of 'approval' should be '1' and the value of 'comments' should be an empty string\n",
    "    If not, the value of 'approval' should be '0' and the value of 'comments' should be a string with the issues and inconsistencies listed.\n",
    "\n",
    "    Technical Specification: {technical_specification}\n",
    "    \n",
    "    Output only a json with keys 'approval' and 'comments'. \n",
    "    \"\"\"\n",
    ")\n",
    "advanced_llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-4\")\n",
    "approval_chain = LLMChain(llm=advanced_llm, prompt=approval_prompt)\n",
    "approval = approval_chain.run({\n",
    "    'technical_specification': specification,\n",
    "    'aspect': 'backend',\n",
    "    'group_size': '4',\n",
    "    'group_experience': \"experienced\"\n",
    "})\n",
    "print(approval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Architect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
