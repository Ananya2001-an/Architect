{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Backend Experiment Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.agents import Tool\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_details=\"\"\"\n",
    "Basically you would put your hackathon idea in a text box\n",
    "and we would run like 3 llm chains in the background\n",
    "One for frontend one for backend, and then feed both chains into the last one which evaluates the two first chains if its feasible or not, and if it isn't, calls the first two chains again\n",
    "The first two will also return design specifications, eg an outline of the frontend and backend\n",
    "maybe another textbox in the frontend for skills/target categories\n",
    "\"\"\"\n",
    "project_technologies=\"\"\"\n",
    "OpenAI API\n",
    "StreamLit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Chain No. 1: Feature Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVP Backend Features:\n",
      "1. Text Processing: The backend should be able to receive the hackathon idea entered in the text box and process it using natural language processing techniques. This includes tasks such as tokenization, part-of-speech tagging, and named entity recognition.\n",
      "\n",
      "2. LLM Chain Execution: The backend should execute three LLM (Language Model) chains in the background. One chain for the frontend, one for the backend, and one for evaluating the feasibility of the idea. The backend should handle the execution and coordination of these chains.\n",
      "\n",
      "3. Feasibility Evaluation: The backend should evaluate the feasibility of the hackathon idea by comparing the outputs of the frontend and backend LLM chains. It should analyze the generated design specifications and determine if they align with each other. If the evaluation indicates that the idea is not feasible, the backend should trigger the execution of the frontend and backend LLM chains again.\n",
      "\n",
      "Additional Backend Features:\n",
      "1. Skill/Target Category Matching: The backend can include a feature where the frontend provides additional information about the skills or target categories related to the hackathon idea. The backend can process this information and use it to refine the evaluation process. It can match the skills/target categories with the generated design specifications to provide more accurate feasibility evaluation.\n",
      "\n",
      "2. Error Handling and Retry Mechanism: The backend should handle any errors that occur during the execution of the LLM chains or the feasibility evaluation. It should have a retry mechanism in place to handle failures and ensure the smooth functioning of the system.\n",
      "\n",
      "3. User Authentication and Authorization: If the hackathon project involves user-specific features, the backend should include user authentication and authorization mechanisms. This ensures that only authorized users can access and interact with the system.\n",
      "\n",
      "4. Logging and Monitoring: The backend should have logging and monitoring capabilities to track the execution of the LLM chains, feasibility evaluation, and any other backend processes. This helps in debugging, performance monitoring, and identifying any potential issues.\n",
      "\n",
      "5. Scalability and Performance Optimization: As the system may need to handle multiple hackathon ideas simultaneously, the backend should be designed to be scalable and optimized for performance. This can involve techniques such as load balancing, caching, and efficient resource utilization.\n",
      "\n",
      "6. API Integration: The backend can integrate with external APIs, such as the OpenAI API, to leverage additional functionalities or services. This can enhance the capabilities of the system and provide more accurate evaluations or suggestions.\n",
      "\n",
      "7. Data Storage and Retrieval: If the system needs to store and retrieve data, the backend should include a database or data storage mechanism. This allows for persistence of hackathon ideas, user information, or any other relevant data.\n",
      "\n",
      "8. Security Measures: The backend should implement security measures to protect the system from potential threats. This can include measures such as input validation, data encryption, and secure communication protocols.\n",
      "\n",
      "9. Error Reporting and Notifications: The backend can include error reporting and notification mechanisms to inform the system administrators or users about any errors or issues that occur during the execution or evaluation process. This helps in timely resolution of problems and ensures smooth user experience.\n",
      "\n",
      "10. Documentation and API Reference: The backend should provide comprehensive documentation and API reference for developers who want to integrate or interact with the system. This includes clear instructions, examples, and guidelines on how to use the backend features and APIs effectively.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-3.5-turbo\")\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"project_details\", \"project_technologies\"],\n",
    "    template=\"\"\"\n",
    "    Given the following project description and tech stack, identify and elaborate on the key backend features that would be necessary for development. The backend features should not involve any frontend components or styling. The backend features should be described in terms of capabilities.\n",
    "    This project is a hackathon project. Break apart the features into MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "    Project description: {project_details}\n",
    "    Technologies: {project_technologies}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "backend_features = chain.run({\n",
    "    'project_details': project_details,\n",
    "    'project_technologies': project_technologies\n",
    "})\n",
    "print(backend_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chain Two:  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Specification:\n",
      "\n",
      "MVP Backend Features:\n",
      "1. Text Processing:\n",
      "   - Technology: Natural Language Processing (NLP) libraries (e.g., NLTK, spaCy)\n",
      "   - Architecture: The backend should receive the hackathon idea as input and process it using NLP techniques such as tokenization, part-of-speech tagging, and named entity recognition.\n",
      "   - Inputs: Hackathon idea text\n",
      "   - Outputs: Processed text with tokenized words, tagged parts of speech, and recognized named entities.\n",
      "\n",
      "2. LLM Chain Execution:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should execute three LLM chains (one for frontend, one for backend, and one for feasibility evaluation) in the background.\n",
      "   - Inputs: None\n",
      "   - Outputs: Generated design specifications from each LLM chain.\n",
      "\n",
      "3. Feasibility Evaluation:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should compare the outputs of the frontend and backend LLM chains to evaluate the feasibility of the hackathon idea.\n",
      "   - Inputs: Generated design specifications from frontend and backend LLM chains\n",
      "   - Outputs: Feasibility evaluation result (feasible or not feasible)\n",
      "\n",
      "Additional Backend Features:\n",
      "1. Skill/Target Category Matching:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend can process additional information about skills or target categories related to the hackathon idea provided by the frontend. It can match these with the generated design specifications to refine the evaluation process.\n",
      "   - Inputs: Additional information about skills or target categories\n",
      "   - Outputs: Refined feasibility evaluation result\n",
      "\n",
      "2. Error Handling and Retry Mechanism:\n",
      "   - Technology: Python\n",
      "   - Architecture: The backend should handle errors during LLM chain execution or feasibility evaluation. It should have a retry mechanism to handle failures and ensure system functionality.\n",
      "   - Inputs: None\n",
      "   - Outputs: Error handling and retry mechanism\n",
      "\n",
      "3. User Authentication and Authorization:\n",
      "   - Technology: Python, Authentication libraries (e.g., Flask-Login, JWT)\n",
      "   - Architecture: The backend should include user authentication and authorization mechanisms if user-specific features are required. This ensures only authorized users can access and interact with the system.\n",
      "   - Inputs: User credentials\n",
      "   - Outputs: User authentication and authorization status\n",
      "\n",
      "4. Logging and Monitoring:\n",
      "   - Technology: Logging libraries (e.g., Python logging module)\n",
      "   - Architecture: The backend should have logging and monitoring capabilities to track LLM chain execution, feasibility evaluation, and other backend processes. This aids in debugging, performance monitoring, and issue identification.\n",
      "   - Inputs: None\n",
      "   - Outputs: Log files and monitoring data\n",
      "\n",
      "5. Scalability and Performance Optimization:\n",
      "   - Technology: Load balancing tools (e.g., Nginx), caching mechanisms (e.g., Redis), performance optimization techniques\n",
      "   - Architecture: The backend should be designed to handle multiple hackathon ideas simultaneously. Techniques like load balancing, caching, and efficient resource utilization should be employed for scalability and performance optimization.\n",
      "   - Inputs: None\n",
      "   - Outputs: Scalable and optimized backend system\n",
      "\n",
      "6. API Integration:\n",
      "   - Technology: Python, OpenAI API\n",
      "   - Architecture: The backend can integrate with external APIs, such as the OpenAI API, to enhance system capabilities and provide more accurate evaluations or suggestions.\n",
      "   - Inputs: None\n",
      "   - Outputs: Integrated API functionalities\n",
      "\n",
      "7. Data Storage and Retrieval:\n",
      "   - Technology: Database systems (e.g., PostgreSQL, MongoDB)\n",
      "   - Architecture: If data storage and retrieval are required, the backend should include a database or data storage mechanism. This allows for persistence of hackathon ideas, user information, or any other relevant data.\n",
      "   - Inputs: Data to be stored or retrieved\n",
      "   - Outputs: Stored or retrieved data\n",
      "\n",
      "8. Security Measures:\n",
      "   - Technology: Input validation libraries, encryption libraries (e.g., bcrypt), secure communication protocols (e.g., HTTPS)\n",
      "   - Architecture: The backend should implement security measures to protect the system from potential threats. This includes input validation, data encryption, and secure communication protocols.\n",
      "   - Inputs: User inputs, sensitive data\n",
      "   - Outputs: Secured system\n",
      "\n",
      "9. Error Reporting and Notifications:\n",
      "   - Technology: Notification libraries (e.g., email notifications, Slack integration)\n",
      "   - Architecture: The backend can include error reporting and notification mechanisms to inform system administrators or users about any errors or issues during execution or evaluation. This ensures timely resolution and a smooth user experience.\n",
      "   - Inputs: Error or issue notifications\n",
      "   - Outputs: Error reports and notifications\n",
      "\n",
      "10. Documentation and API Reference:\n",
      "    - Technology: Documentation tools (e.g., Sphinx, Swagger)\n",
      "    - Architecture: The backend should provide comprehensive documentation and API reference for developers who want to integrate or interact with the system. This includes clear instructions, examples, and guidelines on using backend features and APIs effectively.\n",
      "    - Inputs: None\n",
      "    - Outputs: Documentation and API reference\n"
     ]
    }
   ],
   "source": [
    "specification_prompt = PromptTemplate(\n",
    "    input_variables=[\"backend_features\", \"project_technologies\"],\n",
    "    template=\"\"\"\n",
    "    Given the extracted backend features and the specified skills/technologies, create a detailed technical specification. \n",
    "    This specification should include the technologies to be used, the architecture, the different routes/endpoints, their inputs and outputs, and any potential hardware and startup costs.\n",
    "    However, they should be split into two categories: MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "    You should ignore the technologies for the frontend and focus on the backend.\n",
    "    Please also mention any other technical considerations.\n",
    "    \n",
    "    Backend Features: {backend_features}\n",
    "    \n",
    "    Project Technologies: {project_technologies}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "specification_chain = LLMChain(llm=llm, prompt=specification_prompt)\n",
    "specification = specification_chain.run({\n",
    "    'backend_features': backend_features,\n",
    "    'project_technologies': project_technologies\n",
    "})\n",
    "print(specification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chain Three: AI Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"approval\": \"1\", \"comments\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "approval_prompt = PromptTemplate(\n",
    "    input_variables=[\"technical_specification\", \"aspect\", \"group_size\", \"group_experience\"],\n",
    "    template=\"\"\"\n",
    "    Given the developed technical specification, conduct a thorough review of the MVP Features only for any inconsistencies or issues. \n",
    "    Also, evaluate whether the MVP Features, can be realistically completed within the two day hackathon for {group_size} people, considering the complexity and the technology stack required.\n",
    "    \n",
    "    The MVP Features are specifically listed under the heading 'MVP Features'. \n",
    "    Please completely disregard any features or sections listed under 'Additional Features' or any similar headers.\n",
    "    This specification is only for the {aspect} aspect of the project, and should not be evaluated for other aspects.\n",
    "\n",
    "    Answer this question: Can the MVP Features be realistically completed within the two day hackathon for {group_size} people with this skill level: {group_experience}?\n",
    "    Output only a json with keys 'approval' and 'comments'. \n",
    "    If yes, the value of 'approval' should be '1' and the value of 'comments' should be an empty string\n",
    "    If not, the value of 'approval' should be '0' and the value of 'comments' should be a string with the issues and inconsistencies listed.\n",
    "\n",
    "    Technical Specification: {technical_specification}\n",
    "    \n",
    "    Output only a json with keys 'approval' and 'comments'. \n",
    "    \"\"\"\n",
    ")\n",
    "advanced_llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-4\")\n",
    "approval_chain = LLMChain(llm=advanced_llm, prompt=approval_prompt)\n",
    "approval = approval_chain.run({\n",
    "    'technical_specification': specification,\n",
    "    'aspect': 'backend',\n",
    "    'group_size': '4',\n",
    "    'group_experience': \"experienced\"\n",
    "})\n",
    "print(approval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Architect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
